{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framework: TensorFlow2 + Keras (можно використовувати Pytorch)\n",
    "\n",
    "1. Повнозв'язані нейронні мережі\n",
    "Вирішіть завдання класифікації даних, з якими ви працювали в лабораторній № 1 за допомогою повнозв’язаної нейромережі прямого поширення (fully connected feed-forward network). Результати порівняйте з одержаними раніше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2499 entries, 0 to 2498\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    2499 non-null   int64  \n",
      " 1   price         2499 non-null   int64  \n",
      " 2   brand         2499 non-null   object \n",
      " 3   model         2499 non-null   object \n",
      " 4   year          2499 non-null   int64  \n",
      " 5   title_status  2499 non-null   object \n",
      " 6   mileage       2499 non-null   float64\n",
      " 7   color         2499 non-null   object \n",
      " 8   vin           2499 non-null   object \n",
      " 9   lot           2499 non-null   int64  \n",
      " 10  state         2499 non-null   object \n",
      " 11  country       2499 non-null   object \n",
      " 12  condition     2499 non-null   object \n",
      "dtypes: float64(1), int64(4), object(8)\n",
      "memory usage: 253.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0  price      brand    model  year   title_status   mileage  \\\n",
       " 0           0   6300     toyota  cruiser  2008  clean vehicle  274117.0   \n",
       " 1           1   2899       ford       se  2011  clean vehicle  190552.0   \n",
       " 2           2   5350      dodge      mpv  2018  clean vehicle   39590.0   \n",
       " 3           3  25000       ford     door  2014  clean vehicle   64146.0   \n",
       " 4           4  27700  chevrolet     1500  2018  clean vehicle    6654.0   \n",
       " \n",
       "     color                  vin        lot       state country      condition  \n",
       " 0   black    jtezu11f88k007763  159348797  new jersey     usa   10 days left  \n",
       " 1  silver    2fmdk3gc4bbb02217  166951262   tennessee     usa    6 days left  \n",
       " 2  silver    3c4pdcgg5jt346413  167655728     georgia     usa    2 days left  \n",
       " 3    blue    1ftfw1et4efc23745  167753855    virginia     usa  22 hours left  \n",
       " 4     red    3gcpcrec2jg473991  167763266     florida     usa  22 hours left  ,\n",
       " None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Завантаження датасету\n",
    "file_path = 'USA_cars_datasets.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Відображення перших кількох рядків для аналізу структури даних\n",
    "data.head(), data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   price      brand    model  year   title_status   mileage   color  \\\n",
       " 0   6300     toyota  cruiser  2008  clean vehicle  274117.0   black   \n",
       " 1   2899       ford       se  2011  clean vehicle  190552.0  silver   \n",
       " 2   5350      dodge      mpv  2018  clean vehicle   39590.0  silver   \n",
       " 3  25000       ford     door  2014  clean vehicle   64146.0    blue   \n",
       " 4  27700  chevrolet     1500  2018  clean vehicle    6654.0     red   \n",
       " \n",
       "         state      condition price_category  \n",
       " 0  new jersey   10 days left            low  \n",
       " 1   tennessee    6 days left            low  \n",
       " 2     georgia    2 days left            low  \n",
       " 3    virginia  22 hours left           high  \n",
       " 4     florida  22 hours left           high  ,\n",
       " low       834\n",
       " medium    833\n",
       " high      832\n",
       " Name: price_category, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Визначимо категорії для price: низький, середній, високий\n",
    "# Використовуємо квантильний розподіл\n",
    "data['price_category'] = pd.qcut(data['price'], q=3, labels=['low', 'medium', 'high'])\n",
    "\n",
    "# Видалимо неінформативні колонки\n",
    "data_cleaned = data.drop(columns=['Unnamed: 0', 'vin', 'lot', 'country'])\n",
    "\n",
    "# Перевіримо розподіл цільової змінної та новий датасет\n",
    "price_distribution = data['price_category'].value_counts()\n",
    "data_cleaned.head(), price_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\denis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1999, 299), (500, 299), (1999,), (500,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Вибір числових і категоріальних колонок\n",
    "numeric_columns = ['year', 'mileage']\n",
    "categorical_columns = ['brand', 'model', 'title_status', 'color', 'state', 'condition']\n",
    "\n",
    "# Нормалізація числових колонок\n",
    "scaler = StandardScaler()\n",
    "data_cleaned[numeric_columns] = scaler.fit_transform(data_cleaned[numeric_columns])\n",
    "\n",
    "# One-hot encoding для категоріальних змінних\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "categorical_encoded = encoder.fit_transform(data_cleaned[categorical_columns])\n",
    "categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Об'єднання всіх ознак\n",
    "features = pd.concat([data_cleaned[numeric_columns], categorical_encoded_df], axis=1)\n",
    "target = data_cleaned['price_category']\n",
    "\n",
    "# Розділення на тренувальний і тестовий набори\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)\n",
    "\n",
    "# Перевіримо розміри отриманих наборів\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренувальний набір: 1999 прикладів із 299 ознаками.\n",
    "Тестовий набір: 500 прикладів із 299 ознаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 2s 8ms/step - loss: 0.9631 - accuracy: 0.5503 - val_loss: 0.8076 - val_accuracy: 0.6900\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.7231 - accuracy: 0.7044 - val_loss: 0.6359 - val_accuracy: 0.7860\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.7699 - val_loss: 0.5824 - val_accuracy: 0.7820\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.8049 - val_loss: 0.5460 - val_accuracy: 0.7940\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.8199 - val_loss: 0.5356 - val_accuracy: 0.7880\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8429 - val_loss: 0.5371 - val_accuracy: 0.7940\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8479 - val_loss: 0.5443 - val_accuracy: 0.7840\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8584 - val_loss: 0.5315 - val_accuracy: 0.7820\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8724 - val_loss: 0.5437 - val_accuracy: 0.7800\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3050 - accuracy: 0.8804 - val_loss: 0.5521 - val_accuracy: 0.7800\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2880 - accuracy: 0.8884 - val_loss: 0.5751 - val_accuracy: 0.7920\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.8944 - val_loss: 0.5822 - val_accuracy: 0.7800\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2631 - accuracy: 0.9025 - val_loss: 0.6043 - val_accuracy: 0.7900\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.9025 - val_loss: 0.6021 - val_accuracy: 0.7780\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2449 - accuracy: 0.9085 - val_loss: 0.5966 - val_accuracy: 0.7820\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2237 - accuracy: 0.9120 - val_loss: 0.6195 - val_accuracy: 0.7760\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9180 - val_loss: 0.6356 - val_accuracy: 0.7860\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2027 - accuracy: 0.9205 - val_loss: 0.6535 - val_accuracy: 0.7880\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1895 - accuracy: 0.9260 - val_loss: 0.6742 - val_accuracy: 0.7880\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1934 - accuracy: 0.9215 - val_loss: 0.6857 - val_accuracy: 0.7860\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9300 - val_loss: 0.6881 - val_accuracy: 0.7700\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1618 - accuracy: 0.9350 - val_loss: 0.7092 - val_accuracy: 0.7840\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.9325 - val_loss: 0.6968 - val_accuracy: 0.7840\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.9320 - val_loss: 0.6952 - val_accuracy: 0.7960\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9375 - val_loss: 0.7208 - val_accuracy: 0.7740\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1572 - accuracy: 0.9395 - val_loss: 0.7462 - val_accuracy: 0.7840\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9415 - val_loss: 0.7582 - val_accuracy: 0.7680\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1433 - accuracy: 0.9490 - val_loss: 0.7600 - val_accuracy: 0.7680\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1351 - accuracy: 0.9495 - val_loss: 0.8083 - val_accuracy: 0.7800\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9520 - val_loss: 0.8029 - val_accuracy: 0.7760\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9500 - val_loss: 0.8305 - val_accuracy: 0.7760\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9520 - val_loss: 0.8321 - val_accuracy: 0.7880\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9515 - val_loss: 0.8502 - val_accuracy: 0.7760\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.9485 - val_loss: 0.8607 - val_accuracy: 0.7700\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9560 - val_loss: 0.8595 - val_accuracy: 0.7800\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1221 - accuracy: 0.9475 - val_loss: 0.8897 - val_accuracy: 0.7860\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9540 - val_loss: 0.8786 - val_accuracy: 0.7720\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9565 - val_loss: 0.9144 - val_accuracy: 0.7800\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9575 - val_loss: 0.9258 - val_accuracy: 0.7700\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.9570 - val_loss: 0.9209 - val_accuracy: 0.7720\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9590 - val_loss: 0.9642 - val_accuracy: 0.7740\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9560 - val_loss: 0.9970 - val_accuracy: 0.7720\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9585 - val_loss: 0.9730 - val_accuracy: 0.7800\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9645 - val_loss: 0.9841 - val_accuracy: 0.7720\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9655 - val_loss: 1.0064 - val_accuracy: 0.7700\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9540 - val_loss: 1.0067 - val_accuracy: 0.7780\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9630 - val_loss: 1.0293 - val_accuracy: 0.7780\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9575 - val_loss: 1.0529 - val_accuracy: 0.7760\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9645 - val_loss: 1.0284 - val_accuracy: 0.7800\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9625 - val_loss: 1.0515 - val_accuracy: 0.7820\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Закодуємо цільову змінну для нейронної мережі\n",
    "y_train_encoded = pd.get_dummies(y_train).values\n",
    "y_test_encoded = pd.get_dummies(y_test).values\n",
    "\n",
    "# Побудова моделі\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')  # 3 класи (low, medium, high)\n",
    "])\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделі\n",
    "history = model.fit(X_train, y_train_encoded, \n",
    "                    validation_data=(X_test, y_test_encoded), \n",
    "                    epochs=50, \n",
    "                    batch_size=32, \n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Згорткові нейронні мережі\n",
    "Вирішіть завдання класифікації зображень за допомогою згорткової (convolutional) нейромережі двома способами\n",
    "а) навчить мережу з нуля (from scratch)\n",
    "б) застосуйте перенесення навчання (transfer learning from pre-trained weights)\n",
    "Порівняйте результати (якщо в обраному датасеті класів забагато, достатньо залишити 3-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\denis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 55s 27ms/step - loss: 0.5978 - accuracy: 0.7806 - val_loss: 0.3770 - val_accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.4113 - accuracy: 0.8499 - val_loss: 0.3012 - val_accuracy: 0.8877\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.3666 - accuracy: 0.8671 - val_loss: 0.2760 - val_accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 102s 54ms/step - loss: 0.3409 - accuracy: 0.8755 - val_loss: 0.2641 - val_accuracy: 0.9021\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.3273 - accuracy: 0.8802 - val_loss: 0.2523 - val_accuracy: 0.9044\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.3110 - accuracy: 0.8876 - val_loss: 0.2392 - val_accuracy: 0.9113\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.3009 - accuracy: 0.8884 - val_loss: 0.2546 - val_accuracy: 0.9076\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.2967 - accuracy: 0.8902 - val_loss: 0.2399 - val_accuracy: 0.9120\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 0.2846 - accuracy: 0.8952 - val_loss: 0.2273 - val_accuracy: 0.9160\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.2789 - accuracy: 0.8971 - val_loss: 0.2274 - val_accuracy: 0.9153\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2274 - accuracy: 0.9153\n",
      "Test Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Завантаження даних\n",
    "train_data = pd.read_csv('fashion-mnist_train.csv')  \n",
    "test_data = pd.read_csv('fashion-mnist_test.csv')   \n",
    "\n",
    "# Відокремлення ознак і міток\n",
    "X_train = train_data.drop('label', axis=1).values\n",
    "y_train = train_data['label'].values\n",
    "\n",
    "X_test = test_data.drop('label', axis=1).values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "# Перетворення табличних даних у формат зображень\n",
    "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0  # Масштабування значень у діапазон [0, 1]\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# One-hot кодування \n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Побудова моделі\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')  # 10 класів\n",
    "])\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделі\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=10, \n",
    "                    batch_size=32)\n",
    "\n",
    "# Оцінка моделі\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\denis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 5s 1us/step\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 87s 44ms/step - loss: 1.1113 - accuracy: 0.6187 - val_loss: 0.8889 - val_accuracy: 0.6813\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 93s 49ms/step - loss: 0.9217 - accuracy: 0.6745 - val_loss: 0.8405 - val_accuracy: 0.6993\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 0.8847 - accuracy: 0.6862 - val_loss: 0.8143 - val_accuracy: 0.7045\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 89s 47ms/step - loss: 0.8644 - accuracy: 0.6942 - val_loss: 0.8037 - val_accuracy: 0.7111\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 90s 48ms/step - loss: 0.8473 - accuracy: 0.6985 - val_loss: 0.7857 - val_accuracy: 0.7186\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 96s 51ms/step - loss: 0.8386 - accuracy: 0.7012 - val_loss: 0.7806 - val_accuracy: 0.7171\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 93s 49ms/step - loss: 0.8314 - accuracy: 0.7040 - val_loss: 0.7729 - val_accuracy: 0.7191\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 105s 56ms/step - loss: 0.8274 - accuracy: 0.7043 - val_loss: 0.7718 - val_accuracy: 0.7198\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 96s 51ms/step - loss: 0.8205 - accuracy: 0.7076 - val_loss: 0.7642 - val_accuracy: 0.7228\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 116s 62ms/step - loss: 0.8171 - accuracy: 0.7083 - val_loss: 0.7644 - val_accuracy: 0.7242\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.7644 - accuracy: 0.7242\n",
      "Test Accuracy (Transfer Learning): 0.72\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, Conv2D, Resizing\n",
    "\n",
    "# Відокремлення ознак і міток\n",
    "X_train = train_data.drop('label', axis=1).values\n",
    "y_train = train_data['label'].values\n",
    "\n",
    "X_test = test_data.drop('label', axis=1).values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "# Перетворення табличних даних у формат зображень\n",
    "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0  # Масштабування значень у діапазон [0, 1]\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# One-hot кодування міток\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Попередньо натренована модель\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3)))\n",
    "\n",
    "# Перетворення зображень 28x28x1 у формат 32x32x3 для сумісності\n",
    "resize_layer = Sequential([\n",
    "    Resizing(32, 32),  # Зміна розміру\n",
    "    Conv2D(3, (1, 1))  # Конвертація в 3 канали\n",
    "])\n",
    "\n",
    "X_train_resized = resize_layer(X_train)\n",
    "X_test_resized = resize_layer(X_test)\n",
    "\n",
    "# Замороження ваг базової моделі\n",
    "base_model.trainable = False\n",
    "\n",
    "# Додавання власних шарів\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')  # 10 класів\n",
    "])\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделі\n",
    "history = model.fit(X_train_resized, y_train, \n",
    "                    validation_data=(X_test_resized, y_test), \n",
    "                    epochs=10, \n",
    "                    batch_size=32)\n",
    "\n",
    "# Оцінка моделі\n",
    "test_loss, test_accuracy = model.evaluate(X_test_resized, y_test)\n",
    "print(f\"Test Accuracy (Transfer Learning): {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Рекурентні нейронні мережі\n",
    "Вирішіть задачу класифікації текстів (з якими ви працювали в лабораторній № 2) за допомогою рекурентної нейромережі двома способами:\n",
    "а) навчить мережу і embedding шар з нуля (from scratch)\n",
    "б) використовуючи pretrained word embeddings\n",
    " Результати порівняйте між собою і з одержаними раніш. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 190s 149ms/step - loss: 0.6705 - accuracy: 0.5768 - val_loss: 0.5797 - val_accuracy: 0.7165\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 223s 179ms/step - loss: 0.6269 - accuracy: 0.6413 - val_loss: 0.5623 - val_accuracy: 0.7145\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 217s 174ms/step - loss: 0.5648 - accuracy: 0.7171 - val_loss: 0.6745 - val_accuracy: 0.5454\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 213s 171ms/step - loss: 0.4381 - accuracy: 0.7994 - val_loss: 0.3348 - val_accuracy: 0.8614\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 205s 164ms/step - loss: 0.2654 - accuracy: 0.8985 - val_loss: 0.3158 - val_accuracy: 0.8717\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.3158 - accuracy: 0.8717\n",
      "Test Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Завантаження даних\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Розділення на тренувальний і тестовий набори\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Параметри для обробки тексту\n",
    "max_words = 10000  # Максимальна кількість слів у словнику\n",
    "max_len = 200      # Максимальна довжина тексту\n",
    "\n",
    "# Токенізація тексту\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Перетворення тексту в послідовності\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Заповнення послідовностей до однакової довжини\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Перетворення міток на числовий формат\n",
    "y_train = (y_train == \"positive\").astype(int)\n",
    "y_test = (y_test == \"positive\").astype(int)\n",
    "\n",
    "# Побудова RNN моделі\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделі\n",
    "history = model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test), epochs=5, batch_size=32)\n",
    "\n",
    "# Оцінка моделі\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Завантаження попередньо натренованих ембедингів...\n",
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 307s 242ms/step - loss: 0.6857 - accuracy: 0.5466 - val_loss: 0.6464 - val_accuracy: 0.6610\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 269s 215ms/step - loss: 0.6809 - accuracy: 0.5571 - val_loss: 0.6801 - val_accuracy: 0.5625\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 261s 209ms/step - loss: 0.6853 - accuracy: 0.5427 - val_loss: 0.6884 - val_accuracy: 0.5519\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 259s 207ms/step - loss: 0.6830 - accuracy: 0.5570 - val_loss: 0.6672 - val_accuracy: 0.6181\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 264s 211ms/step - loss: 0.6825 - accuracy: 0.5535 - val_loss: 0.6914 - val_accuracy: 0.5198\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.6914 - accuracy: 0.5198\n",
      "Test Accuracy with FastText: 0.52\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Завантаження даних\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Розділення на тренувальний і тестовий набори\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Параметри для обробки тексту\n",
    "max_words = 10000  # Максимальна кількість слів у словнику\n",
    "max_len = 200      # Максимальна довжина тексту\n",
    "\n",
    "# Токенізація тексту\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Перетворення тексту в послідовності\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Заповнення послідовностей до однакової довжини\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Перетворення міток на числовий формат\n",
    "y_train = (y_train == \"positive\").astype(int)\n",
    "y_test = (y_test == \"positive\").astype(int)\n",
    "\n",
    "# Завантаження FastText\n",
    "print(\"Завантаження попередньо натренованих ембедингів...\")\n",
    "fasttext_model = KeyedVectors.load_word2vec_format('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz', binary=False)\n",
    "\n",
    "# Побудова матриці ембедингів\n",
    "embedding_dim = 300  # Розмірність векторів FastText\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        if word in fasttext_model:\n",
    "            embedding_matrix[i] = fasttext_model[word]\n",
    "\n",
    "# Побудова RNN моделі з попередньо натренованими ембедингами\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim,\n",
    "              weights=[embedding_matrix],\n",
    "              input_length=max_len,\n",
    "              trainable=False),  # Попередньо натреновані ваги не оновлюються\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделі\n",
    "history = model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test), epochs=5, batch_size=32)\n",
    "\n",
    "# Оцінка моделі\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Accuracy with FastText: {test_accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
